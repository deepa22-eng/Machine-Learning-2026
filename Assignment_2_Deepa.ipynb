{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepa22-eng/Machine-Learning-2026/blob/main/Assignment_2_Deepa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chemical Applications of Machine Learning (CHEM 4930/5610) - Spring 2026\n",
        "\n",
        "### Assignment 2 - Deadline 2/3/2026\n",
        "Points 10\n",
        "\n",
        "#### General Comments\n",
        "All figures and graph should have approriate labels on the two axis, and should include a legend with appropriate labels of the different plots.\n",
        "\n",
        "The notebook should be return in working format. That is, I should be able to reset all the output and re-run all the cells and get the same results as you obtained."
      ],
      "metadata": {
        "id": "mCl_XQfPCKtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You should start by saving a copy of the notebook to your Google Drive so you preserve all changes.**\n",
        "\n",
        "**Please add your name as a suffix to the filname**"
      ],
      "metadata": {
        "id": "DJv55sxojLl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2xGg9pFN9reK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Student Name**: Deepa Ranabhat\n",
        "\n",
        "**AI usage statement:**\n",
        "Used ChatGPT basically for generating the python code and understand them how to implement them for the data analysis"
      ],
      "metadata": {
        "id": "Putv2cBPVon5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1 - 10 points\n",
        "\n",
        "In this task, we will consider the Bradley Melting Point Dataset, which is curated chemical dataset with melting points of around 3,000 chemical compounds, see [here](https://www.kaggle.com/datasets/aliffaagnur/melting-point-chemical-dataset/data).\n",
        "\n",
        "This dataset is stored in a comma-separated values (csv) file, which is common format used to start data in text files. We can load this into a pandas DataFrame using the `load_csv` function.\n",
        "\n",
        "In this dataset, we have the compounds names, SMILES strings, and the melting point in Celsius.\n",
        "\n",
        "#### A)\n",
        "Identify in the dataset the chemical compounds with the 5 lowest melting points and 5 highest melting points and visualize their 2D chemical structure using RDKit and the [mols2grid package](https://mols2grid.readthedocs.io/en/latest/), where you display the melting point values on the grid, see [here](https://colab.research.google.com/github/PatWalters/practical_cheminformatics_tutorials/blob/main/fundamentals/A_Whirlwind_Introduction_To_The_RDKit.ipynb#scrollTo=N3CR7rMF3sg7) for an example of the usage of mols2grid.\n",
        "\n",
        "#### B)\n",
        "Calculate the following properties for the molecules using RDKIt:\n",
        "- The molecular weight\n",
        "- The number of heavy atoms\n",
        "- Number of hydrogen bond acceptors\n",
        "- Number of hydrogen bond donors\n",
        "- [Octanol-water partition coefficient - LogP](https://pubs-acs-org.libproxy.library.unt.edu/doi/10.1021/ci990307l)\n",
        "- [Topological polar surface area (TPSA) descriptor](https://pubs-acs-org.libproxy.library.unt.edu/doi/abs/10.1021/jm000942e)\n",
        "- Topological polar surface area (TPSA) descriptor, including S and P atoms, see [here](https://www.rdkit.org/docs/RDKit_Book.html#implementation-of-the-tpsa-descriptor)\n",
        "\n",
        "Note: for some of the molecules, the TPSA descriptor will give a value of zero. When doing any analysis for the TPSA descriptor, you should ignore these values.\n",
        "\n",
        "#### C)\n",
        "Write out to a new csv file values of all the properties calculated in B) along with the compound names, SMILES strings, and the melting point in Celsius. Here, when writing this file, you should ignore any compounds where the SMILES conversion did not work correctly.\n",
        "\n",
        "#### D)\n",
        "Perform a linear regression analysis using scikit-learn where you look at the correlation of each of the properties calculated in B) with melting temperature. Here, each property should be considered individually.\n",
        "\n",
        "To avoid outliers, filter out (i.e., remove) the compounds with the lowest 10% and the highest 10% melting temperature. Make a histogram that shows this filtering. Furthermore, for each property, filter out the compounds with lowest 10% and highest 10% values (again making a histogram that shows this filtering). Only consider the joint remaining compounds in your linear regression analysis for each property.\n",
        "\n",
        "When performing the linear regression, employ a 70%/30% training/test split.\n",
        "\n",
        "Calculate the coefficient of determination, $R^2$, for both the training dataset and the test dataset and report both.\n",
        "\n",
        "You should make figure that shows the data along with the linear curve coming from the linear regression. In the figure, it should be clear which data points are in the training and test set (e.g., by having them in different colors). Include the $R^2$ values on the figure.\n",
        "\n",
        "From your analysis, which of the properties correlates best with the melting temperature?\n",
        "\n",
        "#### E)\n",
        "For two of the properties from D) (e.g., the ones that correlate best with the melting point), perform [RANSAC](https://en.wikipedia.org/wiki/Random_sample_consensus) regression, which is method that takes outliers into account when performing linear regression and does not include them in the final modeling, see [here](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ransac.html).\n",
        "\n",
        "In the figure, it should be clear which data points are in inlier set and which are in the outlier set (e.g., by showing them in different colors).\n"
      ],
      "metadata": {
        "id": "21OlZAEAEQXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bash script to download all the dataset. Don't worry if you don't understand it\n",
        "%%bash\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/valsson-group/UNT-ChemicalApplicationsOfMachineLearning-Spring2026/refs/heads/main/Assignment-2/\"\n",
        "dataset_filename=\"BradleyDoublePlusGoodMeltingPointDataset.csv\"\n",
        "\n",
        "rm -f ${dataset_filename}\n",
        "\n",
        "wget ${url}/${dataset_filename} &> /dev/null\n",
        "\n",
        "ls"
      ],
      "metadata": {
        "id": "tHzH30mufwos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A)  Chemical compounds with the 5 lowest melting points and 5 highest melting points and visualize their 2D chemical structure using RDKit and the mols2grid package"
      ],
      "metadata": {
        "id": "8lok91F7iO07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "NUhO3OoKUGdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"BradleyDoublePlusGoodMeltingPointDataset.csv\")"
      ],
      "metadata": {
        "id": "hWUaEtvlihrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print (data_mp.keys)\n",
        "print(list(data.keys()))"
      ],
      "metadata": {
        "id": "1-YJ1MxPir6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"mpC\"]"
      ],
      "metadata": {
        "id": "x9ToyVVui3zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melting_point_C= data [\"mpC\"]\n",
        "print (melting_point_C)"
      ],
      "metadata": {
        "id": "AkWHkyCJjG82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lowest_5_molecules = np.argpartition(melting_point_C,5)[:5]\n",
        "print (lowest_5_molecules)"
      ],
      "metadata": {
        "id": "AIlv8ziplC8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['name', 'smiles', 'mpC']].iloc[lowest_5_molecules]"
      ],
      "metadata": {
        "id": "akJ5q9q7lc6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highest_5_molecules = np.argpartition(melting_point_C,-5)[-5:]\n",
        "print (highest_5_molecules)"
      ],
      "metadata": {
        "id": "bCUPr8rsljO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['name', 'smiles', 'mpC']].iloc[highest_5_molecules]"
      ],
      "metadata": {
        "id": "RsFhzwxQlqoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the %%capture command will surpress output to screen\n",
        "%%capture\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    !pip install rdkit mols2grid"
      ],
      "metadata": {
        "id": "nLj4lWyJsFs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import mols2grid\n"
      ],
      "metadata": {
        "id": "AQRkssMemGKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# by passing the dataframe, and giving the column with the SMILES string, we can\n",
        "# plot all molecules\n",
        "# we can also add information to the figures by using the subset variable\n",
        "mols2grid.display(data,smiles_col='smiles',subset=['img','name','smiles','mpC'])"
      ],
      "metadata": {
        "id": "QunoZixgsKaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# by passing the dataframe, and giving the column with the SMILES string, we can\n",
        "# plot all molecules\n",
        "# we can also add information to the figures by using the subset variable\n",
        "# Here we also format the string for the melting point to show the C.\n",
        "\n",
        "def mp_str(x):\n",
        "    return f'{x:.2f} C'\n",
        "\n",
        "mols2grid.display(data.iloc[lowest_5_molecules],smiles_col='smiles',subset=['img','name','mpC'], transform={\"mpC\": mp_str})"
      ],
      "metadata": {
        "id": "Ts-4gEzLspgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def mp_str(x):\n",
        "    return f'{x:.2f} C'\n",
        "\n",
        "mols2grid.display(data.iloc[highest_5_molecules],smiles_col='smiles',subset=['img','name','mpC'], transform={\"mpC\": mp_str})"
      ],
      "metadata": {
        "id": "GxgUhIvUseoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B)\n",
        "Calculate the following properties for the molecules using RDKIt:\n",
        "\n",
        "The molecular weight\n",
        "The number of heavy atoms\n",
        "Number of hydrogen bond acceptors\n",
        "Number of hydrogen bond donors\n",
        "Octanol-water partition coefficient - LogP\n",
        "Topological polar surface area (TPSA) descriptor\n",
        "Topological polar surface area (TPSA) descriptor, including S and P atoms"
      ],
      "metadata": {
        "id": "fnhUrXomX5wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit.Chem import Descriptors, rdMolDescriptors\n"
      ],
      "metadata": {
        "id": "kE5hn2XgIwNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Descriptors.__\")\n",
        "for des in Descriptors._descList: print(\"-\",des[0])"
      ],
      "metadata": {
        "id": "zh-Zqm08JQmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function calculates the MolWt', 'HeavyAtomCount', 'LogP', 'HBA', 'HBD', 'TPSA', 'TPSA_S_P'\n",
        "# from a SMILES string using RDKit. If the SMILES is invalid,\n",
        "# it returns NaN instead of causing an error.\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "\n",
        "def molecular_weight(smi):\n",
        "  mol = Chem.MolFromSmiles(smi)\n",
        "  if mol is not None:\n",
        "    return Descriptors.MolWt(mol)\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "def Heavy_atom_count(smi):\n",
        "  mol = Chem.MolFromSmiles(smi)\n",
        "  if mol is not None:\n",
        "    return Descriptors.HeavyAtomCount(mol)\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "def mol_logP(smi):\n",
        "  mol = Chem.MolFromSmiles(smi)\n",
        "  if mol is not None:\n",
        "    return Descriptors.MolLogP(mol)\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "def hba (smi):\n",
        "  mol = Chem.MolFromSmiles(smi)\n",
        "  if mol is not None:\n",
        "    return rdMolDescriptors.CalcNumHBA(mol)\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "def hbd (smi):\n",
        "  mol = Chem.MolFromSmiles(smi)\n",
        "  if mol is not None:\n",
        "    return rdMolDescriptors.CalcNumHBD(mol)\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "def tpsa (smi):\n",
        "  mol = Chem.MolFromSmiles(smi)\n",
        "  if mol is not None:\n",
        "    return rdMolDescriptors.CalcTPSA(mol)\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def tpsa_sp(smi):\n",
        "  mol = Chem.MolFromSmiles(smi)\n",
        "  if mol is not None:\n",
        "    return rdMolDescriptors.CalcTPSA(mol, includeSandP= True)\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SQ__Qd08JTXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we calculate some property and add that to the dataframe\n",
        "data['MolWt'] = [molecular_weight(smi) for smi in data['smiles']]\n",
        "data['HeavyAtomCount'] = [Heavy_atom_count(smi) for smi in data['smiles']]\n",
        "data['LogP'] = [mol_logP(smi) for smi in data['smiles']]\n",
        "data['HBA'] = [hba(smi) for smi in data['smiles']]\n",
        "data['HBD'] = [hbd(smi) for smi in data['smiles']]\n",
        "data['TPSA'] = [tpsa(smi) for smi in data['smiles']]\n",
        "data['TPSA_S_P'] = [tpsa_sp(smi)for smi in data['smiles']]"
      ],
      "metadata": {
        "id": "KqtJp1CdKbJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "Jlcn0oP3PPzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where any key molecular descriptor is missing (NaN).\n",
        "# This ensures all molecules used in regression/plots have complete data.\n",
        "\n",
        "data_ignore_nan = data.dropna(\n",
        "    subset=['MolWt', 'HeavyAtomCount', 'LogP', 'HBA', 'HBD', 'TPSA', 'TPSA_S_P']\n",
        ")\n"
      ],
      "metadata": {
        "id": "DcCD_ZWlVhrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ignore_nan"
      ],
      "metadata": {
        "id": "DYOkZlr2jZuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) New csv file values of all the properties calculated in B) along with the compound names, SMILES strings, and the melting point in Celsius."
      ],
      "metadata": {
        "id": "QW17cJmsPtKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_ignore_nan.to_csv(\"test_with_descriptors.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Tz_ti-b2JGd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head test_with_descriptors.csv"
      ],
      "metadata": {
        "id": "kHFZQejqJn_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ignore_nan[[ 'key', 'name', 'MolWt', 'HeavyAtomCount', 'LogP', 'HBA', 'HBD', 'TPSA', 'TPSA_S_P'] ].to_csv(\"test-subset.csv\",index=False)"
      ],
      "metadata": {
        "id": "7rB53n9_J27Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head test-subset.csv\n"
      ],
      "metadata": {
        "id": "epgrbWfrLVko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D)  Linear regression analysis using scikit-learn"
      ],
      "metadata": {
        "id": "D7SS_9PkL-zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "EpNgZak3L5hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean=pd.read_csv (\"test_with_descriptors.csv\")"
      ],
      "metadata": {
        "id": "hyRm8L3sP6Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(data.keys()))"
      ],
      "metadata": {
        "id": "2hbx5L3AQR0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean"
      ],
      "metadata": {
        "id": "uaMzr4ueQ1j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melting Point"
      ],
      "metadata": {
        "id": "DfGR5lZyqCOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp_values = data_clean[\"mpC\"].values"
      ],
      "metadata": {
        "id": "cUjet2PQSEDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we use the np.percentile function to find 10-th percentile and 90-th percentile of the dataset\n",
        "\n",
        "values_percentile_10 = np.percentile(mp_values,10)\n",
        "values_percentile_90 = np.percentile(mp_values,90)\n",
        "\n",
        "\n",
        "print(values_percentile_10)\n",
        "print(values_percentile_90)"
      ],
      "metadata": {
        "id": "eHNIcRurQk4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #we now create a numpy logical mask to select the elements that are\n",
        "# within 10% of 90% of the data (that is excluding the lowest 10% and\n",
        "# highest 10% values of the data)\n",
        "#\n",
        "# (values > values_percentile_10) selects values that are higher than values_percentile_10\n",
        "# (values < values_percentile_90) selects values that are lower than values_percentile_90\n",
        "# the \"&\" is a boolean AND operator to select elements that fulfil both.\n",
        "mask_10_to_90 = (mp_values > values_percentile_10) & (mp_values < values_percentile_90)\n",
        "\n",
        "values_filtered = mp_values[mask_10_to_90]\n",
        "# the \"~\" is a boolean NOT operator\n",
        "values_filtered_out = mp_values[~mask_10_to_90]\n",
        "\n",
        "print(\"values.size:\",mp_values.size)\n",
        "print(\"values_filtered.size\",values_filtered.size)\n",
        "print(\"values_filtered_out\",values_filtered_out.size)"
      ],
      "metadata": {
        "id": "oLgTCK9VRJBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the data, this will not look correctly as we only\n",
        "# pass the values to the plot function so that the\n",
        "# x-axis is in the index of the element\n",
        "plt.plot(values_filtered,'.',label=\"filtered\")\n",
        "plt.plot(values_filtered_out,'.',label=\"filtered out\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "W14K5ntrRIxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plots that shows the filtering\n",
        "\n",
        "plt.hist(mp_values,bins=100,label=\"Full set\",density=True, alpha=0.5)\n",
        "plt.hist(values_filtered,bins=50,label=\"Filtered set\",density=True, alpha=0.5)\n",
        "plt.xlabel(\"value\")\n",
        "plt.ylabel(\"frequency\")\n",
        "# This is to plot vertical lines for the boundary at 10% and 90%\n",
        "# using axvline. Here we will need to use the plt.gca() to get the\n",
        "# axis object for the plot\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "#plt.show()\n",
        "plt.legend()\n",
        "\n",
        "# note that the KDE plot will \"leak\" outside the boundry\n",
        "# lines as the KDE employs finite width Gaussian kernels\n",
        "sns.kdeplot(mp_values,label=\"Full set\")\n",
        "sns.kdeplot(values_filtered,label=\"Filtered set\")\n",
        "plt.xlabel(\"value\")\n",
        "plt.ylabel(\"density\")\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "ZQCe5TWCRWi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MolWt"
      ],
      "metadata": {
        "id": "gnS2i8B-u1pZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "molwt_values = data_clean[\"MolWt\"].values"
      ],
      "metadata": {
        "id": "d-a7E73KRxU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values_percentile_10 = np.percentile(molwt_values,10)\n",
        "values_percentile_90 = np.percentile(molwt_values,90)\n",
        "\n",
        "print(values_percentile_10)\n",
        "print(values_percentile_90)"
      ],
      "metadata": {
        "id": "OQr1xDujRxs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_10_to_90 = (molwt_values > values_percentile_10) & (molwt_values < values_percentile_90)\n",
        "\n",
        "values_filtered = molwt_values[mask_10_to_90]\n",
        "# the \"~\" is a boolean NOT operator\n",
        "values_filtered_out = molwt_values[~mask_10_to_90]\n",
        "\n",
        "#For regression (molwt + mpC together)\n",
        "data_molwt_filtered = data_clean[mask_10_to_90]\n",
        "\n",
        "print(\"values.size:\",molwt_values.size)\n",
        "print(\"values_filtered.size\",values_filtered.size)\n",
        "print(\"values_filtered_out\",values_filtered_out.size)"
      ],
      "metadata": {
        "id": "1W9DtjygVeRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(values_filtered,'.',label=\"filtered\")\n",
        "plt.plot(values_filtered_out,'.',label=\"filtered out\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"MolWt\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ISn_fJP-Vwb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plots that shows the filtering\n",
        "\n",
        "plt.hist(molwt_values,bins=100,label=\"Full set\",density=True, alpha=0.5)\n",
        "plt.hist(values_filtered,bins=50,label=\"Filtered set\",density=True, alpha=0.5)\n",
        "plt.xlabel(\"Molwt\")\n",
        "plt.ylabel(\"frequency\")\n",
        "# This is to plot vertical lines for the boundary at 10% and 90%\n",
        "# using axvline. Here we will need to use the plt.gca() to get the\n",
        "# axis object for the plot\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "#plt.show()\n",
        "plt.legend()\n",
        "\n",
        "# note that the KDE plot will \"leak\" outside the boundry\n",
        "# lines as the KDE employs finite width Gaussian kernels\n",
        "sns.kdeplot(molwt_values,label=\"Full set\")\n",
        "sns.kdeplot(values_filtered,label=\"Filtered set\")\n",
        "plt.xlabel(\"Molwt\")\n",
        "plt.ylabel(\"density\")\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "zsotCfYDWGCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "F8EjgFhJXCsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "X = data_molwt_filtered[['MolWt']].values\n",
        "y = data_molwt_filtered['mpC'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "r2_train = r2_score(y_train, model.predict(X_train))\n",
        "r2_test = r2_score(y_test, model.predict(X_test))\n",
        "print(f\"MolWt → R² train: {r2_train:.3f}, R² test: {r2_test:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Train')\n",
        "plt.scatter(X_test, y_test, color='red', label='Test')\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, model.predict(X_line), color='black', label='Linear fit')\n",
        "plt.xlabel('MolWt')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title(f'MolWt → R² train={r2_train:.2f}, R² test={r2_test:.2f}')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "HbvU9x9LWbrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u2CDWQK9it2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heavy Atoms Count"
      ],
      "metadata": {
        "id": "33Dd-htnivMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heavyatom_values = data_clean[\"HeavyAtomCount\"].values"
      ],
      "metadata": {
        "id": "9I4SBnGfWS79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values_percentile_10 = np.percentile(heavyatom_values,10)\n",
        "values_percentile_90 = np.percentile(heavyatom_values,90)\n",
        "\n",
        "print(values_percentile_10)\n",
        "print(values_percentile_90)\n",
        "\n",
        "mask_10_to_90 = (heavyatom_values > values_percentile_10) & (heavyatom_values < values_percentile_90)\n",
        "\n",
        "values_filtered = heavyatom_values[mask_10_to_90]\n",
        "# the \"~\" is a boolean NOT operator\n",
        "values_filtered_out = heavyatom_values[~mask_10_to_90]\n",
        "\n",
        "#For regression (molwt + mpC together)\n",
        "data_heavyatoms_filtered = data_clean[mask_10_to_90]\n",
        "\n",
        "print(\"values.size:\",heavyatom_values.size)\n",
        "print(\"values_filtered.size\",values_filtered.size)\n",
        "print(\"values_filtered_out\",values_filtered_out.size)\n",
        "\n",
        "plt.plot(values_filtered,'.',label=\"filtered\")\n",
        "plt.plot(values_filtered_out,'.',label=\"filtered out\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Heavyatoms\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "C9zRmtVcWuX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plots that shows the filtering\n",
        "\n",
        "plt.hist(heavyatom_values,bins=100,label=\"Full set\",density=True, alpha=0.5)\n",
        "plt.hist(values_filtered,bins=50,label=\"Filtered set\",density=True, alpha=0.5)\n",
        "plt.xlabel(\"Molwt\")\n",
        "plt.ylabel(\"frequency\")\n",
        "# This is to plot vertical lines for the boundary at 10% and 90%\n",
        "# using axvline. Here we will need to use the plt.gca() to get the\n",
        "# axis object for the plot\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "#plt.show()\n",
        "plt.legend()\n",
        "\n",
        "# note that the KDE plot will \"leak\" outside the boundry\n",
        "# lines as the KDE employs finite width Gaussian kernels\n",
        "sns.kdeplot(heavyatom_values,label=\"Full set\")\n",
        "sns.kdeplot(values_filtered,label=\"Filtered set\")\n",
        "plt.xlabel(\"HeavyAtom\")\n",
        "plt.ylabel(\"density\")\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "C6arG_WsWuqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "X = data_heavyatoms_filtered[['MolWt']].values\n",
        "y = data_heavyatoms_filtered['mpC'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "r2_train = r2_score(y_train, model.predict(X_train))\n",
        "r2_test = r2_score(y_test, model.predict(X_test))\n",
        "print(f\"Heavy Atoms → R² train: {r2_train:.3f}, R² test: {r2_test:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Train')\n",
        "plt.scatter(X_test, y_test, color='red', label='Test')\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, model.predict(X_line), color='black', label='Linear fit')\n",
        "plt.xlabel('HeavyAtoms')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title(f'HeavyAtoms → R² train={r2_train:.2f}, R² test={r2_test:.2f}')\n",
        "plt.legend()\n",
        "plt.show ()"
      ],
      "metadata": {
        "id": "LfFlptMCjBb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HBA"
      ],
      "metadata": {
        "id": "TvY4Eeuhjn72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hba_values = data_clean[\"HBA\"].values\n",
        "values_percentile_10 = np.percentile(hba_values,10)\n",
        "values_percentile_90 = np.percentile(hba_values,90)\n",
        "\n",
        "print(values_percentile_10)\n",
        "print(values_percentile_90)\n",
        "\n",
        "mask_10_to_90 = (hba_values > values_percentile_10) & (hba_values < values_percentile_90)\n",
        "\n",
        "values_filtered = hba_values[mask_10_to_90]\n",
        "# the \"~\" is a boolean NOT operator\n",
        "values_filtered_out = hba_values[~mask_10_to_90]\n",
        "#For regression (molwt + mpC together)\n",
        "data_hba_filtered = data_clean[mask_10_to_90]\n",
        "\n",
        "print(\"values.size:\",hba_values.size)\n",
        "print(\"values_filtered.size\",values_filtered.size)\n",
        "print(\"values_filtered_out\",values_filtered_out.size)\n",
        "\n",
        "plt.plot(values_filtered,'.',label=\"filtered\")\n",
        "plt.plot(values_filtered_out,'.',label=\"filtered out\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"HBA\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "aAmi3F28WvKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plots that shows the filtering\n",
        "\n",
        "plt.hist(hba_values,bins=100,label=\"Full set\",density=True, alpha=0.5)\n",
        "plt.hist(values_filtered,bins=50,label=\"Filtered set\",density=True, alpha=0.5)\n",
        "plt.xlabel(\"HBA\")\n",
        "plt.ylabel(\"frequency\")\n",
        "# This is to plot vertical lines for the boundary at 10% and 90%\n",
        "# using axvline. Here we will need to use the plt.gca() to get the\n",
        "# axis object for the plot\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "#plt.show()\n",
        "plt.legend()\n",
        "\n",
        "# note that the KDE plot will \"leak\" outside the boundry\n",
        "# lines as the KDE employs finite width Gaussian kernels\n",
        "sns.kdeplot(hba_values,label=\"Full set\")\n",
        "sns.kdeplot(values_filtered,label=\"Filtered set\")\n",
        "plt.xlabel(\"HBA\")\n",
        "plt.ylabel(\"density\")\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "AGyR62l1ZHo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "X = data_hba_filtered[['HBA']].values\n",
        "y = data_hba_filtered['mpC'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "r2_train = r2_score(y_train, model.predict(X_train))\n",
        "r2_test = r2_score(y_test, model.predict(X_test))\n",
        "print(f\"HBA → R² train: {r2_train:.3f}, R² test: {r2_test:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Train')\n",
        "plt.scatter(X_test, y_test, color='red', label='Test')\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, model.predict(X_line), color='black', label='Linear fit')\n",
        "plt.xlabel('HBA')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title(f'HBA → R² train={r2_train:.2f}, R² test={r2_test:.2f}')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m5gGhERxjt5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HBD"
      ],
      "metadata": {
        "id": "yjPCRU9wksup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hbd_values = data_clean[\"HBD\"].values\n",
        "values_percentile_10 = np.percentile(hbd_values,10)\n",
        "values_percentile_90 = np.percentile(hbd_values,90)\n",
        "\n",
        "print(values_percentile_10)\n",
        "print(values_percentile_90)\n",
        "\n",
        "mask_10_to_90 = (hbd_values > values_percentile_10) & (hbd_values < values_percentile_90)\n",
        "\n",
        "values_filtered = hbd_values[mask_10_to_90]\n",
        "# the \"~\" is a boolean NOT operator\n",
        "values_filtered_out = hbd_values[~mask_10_to_90]\n",
        "\n",
        "#For regression (molwt + mpC together)\n",
        "data_hbd_filtered = data_clean[mask_10_to_90]\n",
        "\n",
        "print(\"values.size:\",hbd_values.size)\n",
        "print(\"values_filtered.size\",values_filtered.size)\n",
        "print(\"values_filtered_out\",values_filtered_out.size)\n",
        "\n",
        "plt.plot(values_filtered,'.',label=\"filtered\")\n",
        "plt.plot(values_filtered_out,'.',label=\"filtered out\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"HBD\")\n",
        "plt.legend()\n",
        "\n"
      ],
      "metadata": {
        "id": "67lg3DshZH-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plots that shows the filtering\n",
        "\n",
        "plt.hist(hbd_values,bins=100,label=\"Full set\",density=True, alpha=0.5)\n",
        "plt.hist(values_filtered,bins=50,label=\"Filtered set\",density=True, alpha=0.5)\n",
        "plt.xlabel(\"HBD\")\n",
        "plt.ylabel(\"frequency\")\n",
        "# This is to plot vertical lines for the boundary at 10% and 90%\n",
        "# using axvline. Here we will need to use the plt.gca() to get the\n",
        "# axis object for the plot\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "#plt.show()\n",
        "plt.legend()\n",
        "\n",
        "# note that the KDE plot will \"leak\" outside the boundry\n",
        "# lines as the KDE employs finite width Gaussian kernels\n",
        "sns.kdeplot(hbd_values,label=\"Full set\")\n",
        "sns.kdeplot(values_filtered,label=\"Filtered set\")\n",
        "plt.xlabel(\"HBD\")\n",
        "plt.ylabel(\"density\")\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "hNA0qPKEaiv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "X = data_hbd_filtered[['HBD']].values\n",
        "y = data_hbd_filtered['mpC'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "r2_train = r2_score(y_train, model.predict(X_train))\n",
        "r2_test = r2_score(y_test, model.predict(X_test))\n",
        "print(f\"HBD → R² train: {r2_train:.3f}, R² test: {r2_test:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Train')\n",
        "plt.scatter(X_test, y_test, color='red', label='Test')\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, model.predict(X_line), color='black', label='Linear fit')\n",
        "plt.xlabel('HBD')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title(f'HBD → R² train={r2_train:.2f}, R² test={r2_test:.2f}')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "IW5CJe_5j7dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LogP"
      ],
      "metadata": {
        "id": "MI9Du5cdlWpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logp_values = data_clean[\"LogP\"].values\n",
        "values_percentile_10 = np.percentile(logp_values,10)\n",
        "values_percentile_90 = np.percentile(logp_values,90)\n",
        "\n",
        "print(values_percentile_10)\n",
        "print(values_percentile_90)\n",
        "\n",
        "mask_10_to_90 = (logp_values > values_percentile_10) & (logp_values < values_percentile_90)\n",
        "\n",
        "values_filtered = logp_values[mask_10_to_90]\n",
        "# the \"~\" is a boolean NOT operator\n",
        "values_filtered_out = logp_values[~mask_10_to_90]\n",
        "\n",
        "#For regression (molwt + mpC together)\n",
        "data_logP_filtered = data_clean[mask_10_to_90]\n",
        "\n",
        "print(\"values.size:\",logp_values.size)\n",
        "print(\"values_filtered.size\",values_filtered.size)\n",
        "print(\"values_filtered_out\",values_filtered_out.size)\n",
        "\n",
        "plt.plot(values_filtered,'.',label=\"filtered\")\n",
        "plt.plot(values_filtered_out,'.',label=\"filtered out\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"LogP\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "9EMIz_yvajA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plots that shows the filtering\n",
        "\n",
        "plt.hist(logp_values,bins=100,label=\"Full set\",density=True, alpha=0.5)\n",
        "plt.hist(values_filtered,bins=50,label=\"Filtered set\",density=True, alpha=0.5)\n",
        "plt.xlabel(\"LogP\")\n",
        "plt.ylabel(\"frequency\")\n",
        "# This is to plot vertical lines for the boundary at 10% and 90%\n",
        "# using axvline. Here we will need to use the plt.gca() to get the\n",
        "# axis object for the plot\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "#plt.show()\n",
        "plt.legend()\n",
        "\n",
        "# note that the KDE plot will \"leak\" outside the boundry\n",
        "# lines as the KDE employs finite width Gaussian kernels\n",
        "sns.kdeplot(logp_values,label=\"Full set\")\n",
        "sns.kdeplot(values_filtered,label=\"Filtered set\")\n",
        "plt.xlabel(\"LogP\")\n",
        "plt.ylabel(\"density\")\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "R6i3SN9FajcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "X = data_logP_filtered[['LogP']].values\n",
        "y = data_logP_filtered['mpC'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "r2_train = r2_score(y_train, model.predict(X_train))\n",
        "r2_test = r2_score(y_test, model.predict(X_test))\n",
        "print(f\"LogP → R² train: {r2_train:.3f}, R² test: {r2_test:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Train')\n",
        "plt.scatter(X_test, y_test, color='red', label='Test')\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, model.predict(X_line), color='black', label='Linear fit')\n",
        "plt.xlabel('LogP')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title(f'LogP → R² train={r2_train:.2f}, R² test={r2_test:.2f}')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "KLN-YS9sj-ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPSA"
      ],
      "metadata": {
        "id": "XPeaxMJ2l9Ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tpsa_values = data_clean[\"TPSA\"].values\n",
        "values_percentile_10 = np.percentile(tpsa_values,10)\n",
        "values_percentile_90 = np.percentile(tpsa_values,90)\n",
        "\n",
        "print(values_percentile_10)\n",
        "print(values_percentile_90)\n",
        "\n",
        "mask_10_to_90 = (tpsa_values > values_percentile_10) & (tpsa_values < values_percentile_90)\n",
        "\n",
        "values_filtered = tpsa_values[mask_10_to_90]\n",
        "# the \"~\" is a boolean NOT operator\n",
        "values_filtered_out = tpsa_values[~mask_10_to_90]\n",
        "\n",
        "#For regression (molwt + mpC together)\n",
        "data_tpsa_filtered = data_clean[mask_10_to_90]\n",
        "\n",
        "print(\"values.size:\",tpsa_values.size)\n",
        "print(\"values_filtered.size\",values_filtered.size)\n",
        "print(\"values_filtered_out\",values_filtered_out.size)\n",
        "\n",
        "plt.plot(values_filtered,'.',label=\"filtered\")\n",
        "plt.plot(values_filtered_out,'.',label=\"filtered out\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"TPSA\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "y7TH9lWCbBcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plots that shows the filtering\n",
        "\n",
        "plt.hist(tpsa_values,bins=100,label=\"Full set\",density=True, alpha=0.5)\n",
        "plt.hist(values_filtered,bins=50,label=\"Filtered set\",density=True, alpha=0.5)\n",
        "plt.xlabel(\"TPSA\")\n",
        "plt.ylabel(\"frequency\")\n",
        "# This is to plot vertical lines for the boundary at 10% and 90%\n",
        "# using axvline. Here we will need to use the plt.gca() to get the\n",
        "# axis object for the plot\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "#plt.show()\n",
        "plt.legend()\n",
        "\n",
        "# note that the KDE plot will \"leak\" outside the boundry\n",
        "# lines as the KDE employs finite width Gaussian kernels\n",
        "sns.kdeplot(tpsa_values,label=\"Full set\")\n",
        "sns.kdeplot(values_filtered,label=\"Filtered set\")\n",
        "plt.xlabel(\"TPSA\")\n",
        "plt.ylabel(\"density\")\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "vTM1mH8XbBtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "X = data_tpsa_filtered[['TPSA']].values\n",
        "y = data_tpsa_filtered['mpC'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "r2_train = r2_score(y_train, model.predict(X_train))\n",
        "r2_test = r2_score(y_test, model.predict(X_test))\n",
        "print(f\"TPSA → R² train: {r2_train:.3f}, R² test: {r2_test:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Train')\n",
        "plt.scatter(X_test, y_test, color='red', label='Test')\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, model.predict(X_line), color='black', label='Linear fit')\n",
        "plt.xlabel('TPSA')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title(f'TPSA → R² train={r2_train:.2f}, R² test={r2_test:.2f}')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "rixKqs-DkAZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPSA-SP"
      ],
      "metadata": {
        "id": "yWhEWihso3NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tpsa_sp_values = data_clean[\"TPSA_S_P\"].values\n",
        "values_percentile_10 = np.percentile(tpsa_sp_values,10)\n",
        "values_percentile_90 = np.percentile(tpsa_sp_values,90)\n",
        "\n",
        "print(values_percentile_10)\n",
        "print(values_percentile_90)\n",
        "\n",
        "mask_10_to_90 = (tpsa_sp_values > values_percentile_10) & (tpsa_sp_values < values_percentile_90)\n",
        "\n",
        "values_filtered = tpsa_sp_values[mask_10_to_90]\n",
        "# the \"~\" is a boolean NOT operator\n",
        "values_filtered_out = tpsa_sp_values[~mask_10_to_90]\n",
        "\n",
        "#For regression (molwt + mpC together)\n",
        "data_tpsa_sp_filtered = data_clean[mask_10_to_90]\n",
        "\n",
        "print(\"values.size:\",tpsa_sp_values.size)\n",
        "print(\"values_filtered.size\",values_filtered.size)\n",
        "print(\"values_filtered_out\",values_filtered_out.size)\n",
        "\n",
        "plt.plot(values_filtered,'.',label=\"filtered\")\n",
        "plt.plot(values_filtered_out,'.',label=\"filtered out\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"TPSA_SP\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "CnlFAV4gbCEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plots that shows the filtering\n",
        "\n",
        "plt.hist(tpsa_sp_values,bins=100,label=\"Full set\",density=True, alpha=0.5)\n",
        "plt.hist(values_filtered,bins=50,label=\"Filtered set\",density=True, alpha=0.5)\n",
        "plt.xlabel(\"TPSA-SP\")\n",
        "plt.ylabel(\"frequency\")\n",
        "# This is to plot vertical lines for the boundary at 10% and 90%\n",
        "# using axvline. Here we will need to use the plt.gca() to get the\n",
        "# axis object for the plot\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "#plt.show()\n",
        "plt.legend()\n",
        "\n",
        "# note that the KDE plot will \"leak\" outside the boundry\n",
        "# lines as the KDE employs finite width Gaussian kernels\n",
        "sns.kdeplot(tpsa_sp_values,label=\"Full set\")\n",
        "sns.kdeplot(values_filtered,label=\"Filtered set\")\n",
        "plt.xlabel(\"TPSA-SP\")\n",
        "plt.ylabel(\"density\")\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=values_percentile_10, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axvline(x=values_percentile_90, color='black', linestyle='--', linewidth=0.5)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "-bIEdWDycwIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "X = data_tpsa_sp_filtered[['TPSA_S_P']].values\n",
        "y = data_tpsa_sp_filtered['mpC'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "r2_train = r2_score(y_train, model.predict(X_train))\n",
        "r2_test = r2_score(y_test, model.predict(X_test))\n",
        "print(f\"TPSA_SP → R² train: {r2_train:.3f}, R² test: {r2_test:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Train')\n",
        "plt.scatter(X_test, y_test, color='red', label='Test')\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, model.predict(X_line), color='black', label='Linear fit')\n",
        "plt.xlabel('TPSA_SP')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title(f'TPSA_SP → R² train={r2_train:.2f}, R² test={r2_test:.2f}')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "z3UoLVP5dAhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DYUgczxedA-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E) Performing RANSAC regression for molweight and TPSA .\n",
        "These two properties correlate best with the melting point."
      ],
      "metadata": {
        "id": "phmRsffRVGPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "B9P1YGM5oL5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X and y from  dataframe\n",
        "X = data_clean[['MolWt']].values   # all data, no filtering\n",
        "y = data_clean['mpC'].values\n",
        "\n",
        "# RANSAC regression\n",
        "ransac = RANSACRegressor(\n",
        "    estimator=LinearRegression(),\n",
        "    min_samples=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "ransac.fit(X, y)\n",
        "\n",
        "# Identify inliers and outliers\n",
        "inlier_mask = ransac.inlier_mask_\n",
        "outlier_mask = ~inlier_mask\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "plt.scatter(X[inlier_mask], y[inlier_mask],\n",
        "            label='Inliers', alpha=0.7)\n",
        "\n",
        "plt.scatter(X[outlier_mask], y[outlier_mask],\n",
        "            label='Outliers', alpha=0.7)\n",
        "\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, ransac.predict(X_line),\n",
        "         color='black', linewidth=2, label='RANSAC fit')\n",
        "\n",
        "plt.xlabel('MolWt')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title('RANSAC Regression: MolWt vs Melting Point')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IkJ6vDeHqKm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# X and y from  dataframe\n",
        "X = data_clean[['TPSA']].values   # all data, no filtering\n",
        "y = data_clean['mpC'].values\n",
        "\n",
        "# RANSAC regression\n",
        "ransac = RANSACRegressor(\n",
        "    estimator=LinearRegression(),\n",
        "    min_samples=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "ransac.fit(X, y)\n",
        "\n",
        "# Identify inliers and outliers\n",
        "inlier_mask = ransac.inlier_mask_\n",
        "outlier_mask = ~inlier_mask\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "plt.scatter(X[inlier_mask], y[inlier_mask],\n",
        "            label='Inliers', alpha=0.7)\n",
        "\n",
        "plt.scatter(X[outlier_mask], y[outlier_mask],\n",
        "            label='Outliers', alpha=0.7)\n",
        "\n",
        "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "plt.plot(X_line, ransac.predict(X_line),\n",
        "         color='black', linewidth=2, label='RANSAC fit')\n",
        "\n",
        "plt.xlabel('TPSA')\n",
        "plt.ylabel('Melting point (°C)')\n",
        "plt.title('RANSAC Regression: TPSA vs Melting Point')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Uo1AugB_U49U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2 - Optional 5 points\n",
        "\n",
        "Here we will consider a dataset of two variables $x$ and $y$ sampled from a two-dimensional probability density $P(x,y)$ that is unknown.\n",
        "\n",
        "The dataset is given as a time series in the file `Dataset_RotatedWQ-Potential.data`.\n",
        "\n",
        "The main task is to perform a Gaussian Mixture Model analysis on this two-dimensional dataset.\n",
        "\n",
        "#### A)\n",
        "Plot the dataset, both the time series and also a scatter plot for the $x$ and $y$ variables.\n",
        "\n",
        "Looking at the scatter plot, how many Gaussian components do you think are needed in the Gaussian Mixture Model analysis?\n",
        "\n",
        "#### B)\n",
        "Using Seaborn (or scikit-learn) estimate the two-dimensional probability density $P(x,y)$ using kernel density estimation.\n",
        "\n",
        "#### C)\n",
        "Perform a Gaussian Mixture Model analysis for a different number of components, and obtain the Bayesian information criterion (bic) and Akaike information criterion (aic) values and based on them identify the optimal number of components (remember that for both a lower value is better).\n",
        "\n",
        "#### D)\n",
        "For the optimal number of components, perform a final Gaussian Mixture Model analysis that you will analyze.\n",
        "\n",
        "- What is the weight of each Gaussian components.\n",
        "\n",
        "- What is the percentage of samples that are hard classifed to each cluster.\n",
        "\n",
        "- Make a scatter plot that shows how the samples are hard classifed to each cluster. In this plot, indicate the center of each Gaussian components.\n",
        "\n",
        "- Make figures that shows how the samples are soft classifed to each cluster (e.g., the probablity that they belong to a given cluster). In each plot, indicate the center of corresponding Gaussian components.\n",
        "\n",
        "- Plot a two-dimensional surface of the $P(x,y)$ estimated by the Gaussian Mixture Model. How does this compare to the KDE plot from B)?\n"
      ],
      "metadata": {
        "id": "PJ7zS06xPVJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bash script to download all the dataset. Don't worry if you don't understand it\n",
        "%%bash\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/valsson-group/UNT-ChemicalApplicationsOfMachineLearning-Spring2026/refs/heads/main/Assignment-2/\"\n",
        "dataset_filename=\"Dataset_RotatedWQ-Potential.data\"\n",
        "\n",
        "rm -f ${dataset_filename}\n",
        "\n",
        "wget ${url}/${dataset_filename} &> /dev/null\n",
        "\n",
        "ls\n",
        "\n"
      ],
      "metadata": {
        "id": "PLEPeyqIVcRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A) Load data + time series + scatter plot"
      ],
      "metadata": {
        "id": "b0idXnLWY0WA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbMM1zTTBvge"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load data\n",
        "# If comma-separated, change delimiter=','\n",
        "data = np.loadtxt(\"Dataset_RotatedWQ-Potential.data\")\n",
        "\n",
        "x = data[:, 0]\n",
        "y = data[:, 1]\n",
        "\n",
        "# Time series plot\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(x, label='x')\n",
        "plt.plot(y, label='y')\n",
        "plt.xlabel(\"Time index\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Time series of x and y\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(x, y, s=5, alpha=0.5)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Scatter plot of x vs y\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) 2D KDE estimate of P(x,y)"
      ],
      "metadata": {
        "id": "_eWcaf1rZNif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "sns.kdeplot(\n",
        "    x=x, y=y,\n",
        "    fill=True,\n",
        "    cmap=\"viridis\",\n",
        "    levels=50\n",
        ")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"2D KDE estimate of P(x, y)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "50ui3tCAY-ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) GMM with different components + BIC/AIC"
      ],
      "metadata": {
        "id": "0mNbBVcVZdM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "X = np.column_stack((x, y))\n",
        "\n",
        "n_components_range = range(1, 7)\n",
        "bic = []\n",
        "aic = []\n",
        "\n",
        "for n in n_components_range:\n",
        "    gmm = GaussianMixture(\n",
        "        n_components=n,\n",
        "        covariance_type='full',\n",
        "        random_state=42\n",
        "    )\n",
        "    gmm.fit(X)\n",
        "    bic.append(gmm.bic(X))\n",
        "    aic.append(gmm.aic(X))\n",
        "\n",
        "# Plot BIC/AIC\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(n_components_range, bic, marker='o', label='BIC')\n",
        "plt.plot(n_components_range, aic, marker='o', label='AIC')\n",
        "plt.xlabel(\"Number of components\")\n",
        "plt.ylabel(\"Criterion value\")\n",
        "plt.title(\"Model selection using BIC and AIC\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XD1i6jG_ZYLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_OPT = 3\n",
        "\n",
        "gmm = GaussianMixture(\n",
        "    n_components=N_OPT,\n",
        "    covariance_type='full',\n",
        "    random_state=42\n",
        ")\n",
        "gmm.fit(X)\n",
        "\n",
        "labels = gmm.predict(X)\n",
        "probs = gmm.predict_proba(X)\n",
        "means = gmm.means_\n",
        "weights = gmm.weights_\n"
      ],
      "metadata": {
        "id": "ph4Yi4FyZ-T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D1) Weight of each Gaussian component"
      ],
      "metadata": {
        "id": "YyLkfZGEbiE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, w in enumerate(weights):\n",
        "    print(f\"Component {i}: weight = {w:.3f}\")\n"
      ],
      "metadata": {
        "id": "NPocd-5VaTg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D2) Percentage of samples hard-classified to each cluster"
      ],
      "metadata": {
        "id": "zILj1G5-bm_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(N_OPT):\n",
        "    perc = np.mean(labels == i) * 100\n",
        "    print(f\"Component {i}: {perc:.2f}% of samples\")\n"
      ],
      "metadata": {
        "id": "n0wIlNqCbpjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D3) Scatter plot — hard classification + centers"
      ],
      "metadata": {
        "id": "0-JFqS7Ubs6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(x, y, c=labels, cmap='tab10', s=5)\n",
        "plt.scatter(means[:,0], means[:,1],\n",
        "            c='black', marker='x', s=100, label='Centers')\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Hard classification by GMM\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tPeGvnNJbvz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D4) Soft classification plots (probabilities)"
      ],
      "metadata": {
        "id": "5zGrtkvvbzzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(N_OPT):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(x, y, c=probs[:, i], cmap='viridis', s=5)\n",
        "    plt.colorbar(label=f\"P(cluster {i})\")\n",
        "    plt.scatter(means[i,0], means[i,1],\n",
        "                c='red', marker='x', s=100)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.title(f\"Soft classification: cluster {i}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KkFGLWWCbzQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D5) 2D surface of\n",
        "𝑃\n",
        "(\n",
        "𝑥\n",
        ",\n",
        "𝑦\n",
        ")\n",
        "P(x,y) from GMM"
      ],
      "metadata": {
        "id": "e0fzKpB-cAcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid\n",
        "x_grid = np.linspace(x.min(), x.max(), 100)\n",
        "y_grid = np.linspace(y.min(), y.max(), 100)\n",
        "Xg, Yg = np.meshgrid(x_grid, y_grid)\n",
        "XY = np.column_stack([Xg.ravel(), Yg.ravel()])\n",
        "\n",
        "Z = np.exp(gmm.score_samples(XY))\n",
        "Z = Z.reshape(Xg.shape)\n",
        "\n",
        "# Surface / contour plot\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.contourf(Xg, Yg, Z, levels=50, cmap='viridis')\n",
        "plt.colorbar(label='P(x,y)')\n",
        "plt.scatter(means[:,0], means[:,1],\n",
        "            c='red', marker='x', s=100)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"GMM estimate of P(x, y)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mA0Q4UebcDpD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}